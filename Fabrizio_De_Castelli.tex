%----------------------------------------------------------------------------------------
%	Machine Learning Assignment Template
%----------------------------------------------------------------------------------------

\documentclass[11pt]{scrartcl}
\newcommand*\student[1]{\newcommand{\thestudent}{{#1}}}

%----------------------------------------------------------------------------------------
%	INSERT HERE YOUR NAME
%----------------------------------------------------------------------------------------

\student{De Castelli Fabrizio}

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Use 8-bit encoding
\usepackage[sc]{mathpazo}
\usepackage{caption, subcaption}
\usepackage{hyperref}
\usepackage{inconsolata}

\usepackage[english]{babel} % English language hyphenation
\usepackage{amsmath, amsfonts} % Math packages
\usepackage{listings} % Code listings, with syntax highlighting
\usepackage{graphicx} % Required for inserting images
\graphicspath{{Figures/}{./}} % Specifies where to look for included images (trailing slash required)
\usepackage{float}

%----------------------------------------------------------------------------------------
%	DOCUMENT MARGINS
%----------------------------------------------------------------------------------------

\usepackage{geometry} % For page dimensions and margins
\geometry{
	paper=a4paper, 
	top=2.5cm, % Top margin
	bottom=3cm, % Bottom margin
	left=3cm, % Left margin
	right=3cm, % Right margin
}

%----------------------------------------------------------------------------------------
%	SECTION TITLES
%----------------------------------------------------------------------------------------

\usepackage{sectsty}
\sectionfont{\vspace{6pt}\centering\normalfont\scshape}
\subsectionfont{\normalfont\bfseries} % \subsection{} styling
\subsubsectionfont{\normalfont\itshape} % \subsubsection{} styling
\paragraphfont{\normalfont\scshape} % \paragraph{} styling

%----------------------------------------------------------------------------------------
%	HEADERS AND FOOTERS
%----------------------------------------------------------------------------------------

\usepackage{scrlayer-scrpage}
\ofoot*{\pagemark} % Right footer
\ifoot*{\thestudent} % Left footer
\cfoot*{} % Centre footer

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{	
	\normalfont\normalsize
	\textsc{Machine Learning\\%
	Universit\`a della Svizzera italiana}\\
	\vspace{25pt}
	\rule{\linewidth}{0.5pt}\\
	\vspace{20pt}
	{\huge Assignment 1}\\
	\vspace{12pt}
	\rule{\linewidth}{1pt}\\
	\vspace{12pt}
}

\author{\LARGE \thestudent}

\date{\normalsize\today}

\begin{document}

\maketitle

%The assignment is split into two parts: you are asked to solve a regression problem, and answer some questions. 
%You can use all the books, material, and help you need. 
%Bear in mind that the questions you are asked are similar to those you may find in the final exam, and are related to very important and fundamental machine learning concepts. 
%As such, sooner or later you will need to learn them to pass the course. 
%We will give you some feedback afterwards.\\


%----------------------------------------------------------------------------------------
%	Tasks
%----------------------------------------------------------------------------------------

\section*{Tasks}


\subsection*{Task 1}
Use the family of models $f(\mathbf{x}, \boldsymbol{\theta}) = \theta_0 + \theta_1 \cdot x_1 + \theta_2 \cdot x_2 + \theta_3 \cdot \sin(x_2) + \theta_4 \cdot x_1 \cdot x_2$ to fit the data. 

\begin{itemize}
	\item [a.] Write in the report the formula of the model substituting parameters $\theta_0, \ldots, \theta_4$ with the estimates you've found:
	$$f(\mathbf{x}, \boldsymbol{\theta}) = 1.31635 - 0.05128 \cdot x_1 - 0.57659 \cdot x_2 + 0.42026 \cdot \sin(x_2) + 0.03686 \cdot x_1 \cdot x_2$$
	\item [b.] Evaluate the test performance of your model using the mean squared error as performance measure.
    $$MSE\ on\ test\ set:\ 0.7516362518990539$$
\end{itemize}


\subsection*{Task 2}
Consider any family of non-linear models of your choice to address the above regression problem.
\begin{itemize}
	\item [a.] Evaluate the test performance of your model using the mean squared error as performance measure. 
 $$MSE\ on\ test\ set:\ 0.7049353122711182$$
	\item [b.] Compare your model with the linear regression of Task 1. Which one is {statistically} better?\\\\
 Statistically, it is better the non-linear family because the linear family implicitly assumes that there is a linear relationship between features and targets and it is not able to learn it. On the other hand, the non-linear family, which can be a simple Feed Forward Neural Network with a non-linearity as activation function of one hidden layer, can learn more complex scenarios where the relationship between the features and targets is not linear.
\end{itemize}

\subsection*{Task 3 (Bonus)}
In the \href{https://github.com/GiorgiaAuroraAdorni/ML-bachelor-course-assignments-sp23}{\textbf{GitHub repository of the course}}, you will find a trained Scikit-learn model that we built using the same dataset you are given. 
This \textit{baseline} model is able to achieve a MSE of \textbf{0.022}, when evaluated on the test set. 
You will get extra points if you provide a model of your choice whose test performance is \textbf{better} (i.e., the MSE is lower) than ours. Of course, you must also tell us why your model is performing better.

%----------------------------------------------------------------------------------------
%	Questions
%----------------------------------------------------------------------------------------
%\newpage
\section*{Questions}

\subsection*{Q1. Training versus Validation}
\begin{itemize}
\item[Q1.1] What is the whole figure about?  
\item[A1.1] The figure refers to a method called \textit{Early Stopping} used to stop the training once the model is no longer improving its performance on a validation set.
\item[Q1.2] Explain the behaviours of the curves in each of the three highlighted sections in the figure, namely (a), (b), and (c).   
\item[A1.2] The smooth red curve is the average of the validation errors generated by random configuration of initial parameters. We aim to find a model which complexity minimizes the red curve. The green curve is generally decreasing with along the x-axis and represent the error, evaluated with a metric, on the training set during the training of our model. The blue curve is the error we get on a reserved portion of the dataset (validation set). It is decreasing with the improvement of underfitting and increasing the more overfitting we have. 

\begin{itemize}
\item[Q1.2.a] Can you identify any signs of overfitting or underfitting in the plot? If yes, explain which sections correspond to which concept.
\item[A1.2.a] The more the number of iteration grows, the more the risk of overfitting increases. That is because we are training our too much on the training set, minimizing its error. In the figure, overfitting can be seen in the section (c). In underfitting we are in the opposite situation: the model is not able to fit data in the correct way (it fits only few of them) and we are getting a very high training, validation and expected test error as well. Thus, overfitting can be seen in section (a).\\
In section (b) there is a compromise of overfitting and underfitting, leading to a better performing model.

\item[Q1.2.b] How can you determine the optimal complexity of the model based on the given plot?
\item[A1.2.b] One could say that the optimal model is the one lying on the blue dotted line because it minimizes the difference between the observed validation error and observed training error. But this is not completely true as that model is biased towards some configuration of the dataset, depending on how it is shuffled. The optimal model is probably the one closer to the red dotted line because it is not biased. \\
Generally, the optimal model is the one that has the best loss performance before the error on the validation set starts increasing (towards section (c)).
\end{itemize}
	
\item[Q1.3] Is there any evidence of high approximation risk? Why? If yes, in which of the below subfigures?  
\item[A1.3] 

\item[Q1.4] Do you think that increasing the model complexity can bring the training error to zero? And the structural risk?  
\item[A1.4] Increasing the model complexity can bring the training error to zero, but with a low probability because all data points are affected by noise. The structural risk is the expected difference between the empirical risk (i.e. the error) and the true risk, so it has 

\item[Q1.5] If the X axis represented the training iterations instead, would you think that the training procedure that generated the figure used early stopping? Explain why. (\textbf{NB:} ignore the subfigures and the dashed vertical lines)
\item[A1.5] Yes, because the more training epochs we do, the more the complexity of the model increases. It can be shown that the number of iterations represent also the model complexity and this is a consequence of overfitting, because we are minimizing the error on the training set by adjusting our parameters.

\end{itemize}

\subsection*{Q2. Linear Regression}
Comment and compare how the (a.) training error, (b.) test error and (c.) coefficients would change in the following cases:
\begin{itemize}
\item[Q2.1] $x_3 = x_1 + 0.2 \cdot x_2$.
\item[A2.1] ~\\

\item[Q2.2] $x_3 = x_1 \cdot x_2 \cdot x_2$
\item[A2.2] ~\\

\item[Q2.3] $x_3$ is a random variable independent from $y$.
\item[A2.3] ~\\

\item[Q2.3] How would your answers change if you were using Lasso Regression?
\item[A2.3] ~\\

\item[Q2.4] Explain the motivation behind Ridge and Lasso regression and their principal differences.
\item[A2.4] ~\\  
\end{itemize}

\subsection*{Q3. Classification}
\begin{itemize}
\item[Q3.1] Your boss asked you to solve the problem using a perceptron, and now he's upset because you are getting poor results. How would you justify the poor performance of your perceptron classifier to your boss?
\item[A3.1] The perceptron is not performing well because it can only solve linearly separable problems. In particular, the perceptron cannot solve the \textit{xor} problem but only the \textit{or} problem. Clearly, the one showed in the picture does not have linearly separable classes. \\
Generally, if we have a network composed of linearities only, we lose power of computation because their composition is still a linear combination of the input.

\item[Q3.2] Would you expect better luck with a neural network with the activation function $h(x) = - x * e^{(-2)}$ for the hidden units?
\item[A3.2] This activation function is still linear, so I am not expecting explicitly better result. We are not sure it will worsen or improve the model, but if it improves it, the gain is not too evident. It might be the case to introduce another activation function that is non-linear.

\item[Q3.3] What are the main differences and similarities between the perceptron and the logistic regression neuron?
\item[A3.3] The main differences are:
\begin{itemize}
    \item They have different activation functions. The perceptron has a Step activation function
    $$f: \mathbb{R} \longrightarrow \mathbb{R},$$
    $$f(x) = 
        \begin{cases}
          1, & \text{if $x \ge 0$}\\
          0, & \text{if $x < 0 $}\\
        \end{cases}
    $$
    while the logistic regression neuron has a sigmoid as activation function
    $$sigmoid(x) = \sigma(x) = \frac{1}{1 + e^{-x}}$$
    \item The role of the neurons are different. The perceptron returns as output a value that represents a class assignment if it is higher than a certain threshold, but it doesn't have other interpretation for the output. \\
    On the other hand, the logistic regression neuron output the probability that the given input can be assigned to a certain class. This comes from the construction of the sigmoid, because $\forall x \in \mathbb{R}\ .\ \sigma(x) \in (0, 1)$
    \item The first one is not continuous, while the second one is continuous and differentiable.
    \item The perceptron neuron is trained by updating weights iteratively, while the other one can be trained with Maximum Likelihood estimation.
\end{itemize}

The main similarities are:
\begin{itemize}
    \item They are both used in architectures to solve binary classification tasks;
    \item They both generate a decision boundary for the classes.
\end{itemize}  .

\end{itemize}

\end{document}
