{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabriDeCastelli/ML-Regression-Assignment/blob/main/deliverable/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DWeu0ia-rlr"
      },
      "source": [
        "# Assignment 1\n",
        "Student: Fabrizio De Castelli\n",
        "\n",
        "--- \n",
        "# IMPORTANT: all the submitted code should be in 2 cells\n",
        "1) How you trained, evaluated and saved your model\n",
        "2) How to load your model from a file, load the data and evaluate the model. Cell 2) should be running independently (even if cell 1 is not run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQdDtLAJ-rlr",
        "outputId": "a3348f58-4d52-4fc5-de29-841e7ff214e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------- T1 ---------\n",
            "theta_hat = [ 1.31635295 -0.05128958 -0.57659976  0.42026517  0.03686637]\n",
            "MSE on training set: 0.696251517689963\n",
            "MSE on test set: 0.7516362518990539\n",
            "-------- T2 ---------\n",
            "MSE on training set: 0.019384844163405014\n",
            "MSE on test set: 0.07082283622259962\n",
            "-------- T3 ---------\n",
            "19/19 [==============================] - 0s 1ms/step\n",
            "MSE on test set: 0.017000295696910944\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import io\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Load data \n",
        "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'\n",
        "response = requests.get(url)\n",
        "data = np.load(io.BytesIO(response.content))\n",
        "\n",
        "# Alternatively yo can load the data from file\n",
        "# data_path = '../data/data.npz' # path to the .npz file storing the data\n",
        "# data = np.load(data_path)\n",
        "\n",
        "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
        "x = data.f.x\n",
        "\n",
        "# y is a Numpy array of shape (n_samples, ) with the targets\n",
        "y = data.f.y\n",
        "\n",
        "# Feature extracion for the task\n",
        "ones = np.ones(shape=(x.shape[0], 1))\n",
        "sin_x2 = np.sin(x[:, 1]).reshape(-1,1)\n",
        "x1_times_x2 = np.multiply(x[:, 0], x[:, 1]).reshape(-1,1)\n",
        "X = np.hstack((ones, x, sin_x2, x1_times_x2)) \n",
        "\n",
        "# T1\n",
        "print('-------- T1 ---------')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error \n",
        "\n",
        "# Generate training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=0)\n",
        "\n",
        "# Init the model\n",
        "linear_regression = LinearRegression(fit_intercept=False)  \n",
        "\n",
        "# Fit data in the model\n",
        "linear_regression.fit(X_train, y_train)\n",
        "\n",
        "# Best computed parameter configuration\n",
        "theta_hat = linear_regression.coef_\n",
        "\n",
        "# Save the model in a pickle file \n",
        "# Uncomment next two instructions to save the nonlinear model\n",
        "\"\"\"\n",
        "with open('linear_regression.pickle', 'wb') as f:\n",
        "  pickle.dump(linear_regression, f, pickle.HIGHEST_PROTOCOL)\n",
        "\"\"\"\n",
        "\n",
        "# Generate prediction on training set and evaluate performance with MSE\n",
        "train_prediction = linear_regression.predict(X_train)\n",
        "train_performance = mean_squared_error(train_prediction, y_train)\n",
        "\n",
        "# Generate prediction on test set and evaluate performance with MSE\n",
        "test_prediction = linear_regression.predict(X_test)\n",
        "test_performance = mean_squared_error(test_prediction, y_test)\n",
        "\n",
        "print('theta_hat = {}'.format(theta_hat))\n",
        "print('MSE on training set: {}'.format(train_performance))\n",
        "print('MSE on test set: {}'.format(test_performance))\n",
        "\n",
        "# T2\n",
        "print('-------- T2 ---------')\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Degree of Polynomial\n",
        "degree = 11\n",
        "\n",
        "# Init polynomial feature extraction\n",
        "pol_feat = PolynomialFeatures(degree=degree, include_bias=False) \n",
        "\n",
        "# Split original dataset\n",
        "x_train, x_test = train_test_split(x, train_size=0.7, shuffle=True, random_state=0)\n",
        "\n",
        "Xpol =  pol_feat.fit_transform(x)\n",
        "\n",
        "# Transform data points with polynomial features\n",
        "Xpol_train = pol_feat.fit_transform(x_train)\n",
        "Xpol_test = pol_feat.fit_transform(x_test)\n",
        "\n",
        "# Init the polynomial fitting model\n",
        "pol_fitting = LinearRegression(fit_intercept=False)  \n",
        "\n",
        "# Fit data in the model\n",
        "pol_fitting.fit(Xpol_train, y_train)\n",
        "\n",
        "# Generate prediction on training set and evaluate performance with MSE\n",
        "train_prediction = pol_fitting.predict(Xpol_train)\n",
        "train_performance = mean_squared_error(train_prediction, y_train)\n",
        "\n",
        "# Generate prediction on test set and evaluate performance with MSE\n",
        "test_prediction = pol_fitting.predict(Xpol_test)\n",
        "test_performance = mean_squared_error(test_prediction, y_test)\n",
        "\n",
        "print('MSE on training set: {}'.format(train_performance))\n",
        "print('MSE on test set: {}'.format(test_performance))\n",
        "\n",
        "print(\"--------- Statistical Comparison  ----------\")\n",
        "\n",
        "# Library to evaluate statistically both models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# In this section I evaluate the score of the linear model\n",
        "linear_model_scores = cross_val_score(linear_regression, X, y, scoring='neg_mean_squared_error', cv=100)\n",
        "linear_model_rmse_scores = np.sqrt(-linear_model_scores)\n",
        "linear_model_rmse_mean = np.mean(linear_model_rmse_scores)\n",
        "\n",
        "# In this section I evaluate the score of the polynomial fitting\n",
        "pol_fitting_scores = cross_val_score(pol_fitting, Xpol, y, scoring='neg_mean_squared_error', cv=100)\n",
        "pol_fitting_rmse_scores = np.sqrt(-pol_fitting_scores)\n",
        "pol_fitting_rmse_mean = np.mean(pol_fitting_rmse_scores)\n",
        "\n",
        "print(\"Linear Regression mean RSE:\", linear_model_rmse_mean)\n",
        "print(\"Polynomial FItting mean RSE:\", pol_fitting_rmse_mean)\n",
        "\n",
        "# T3 (Bonus)\n",
        "\n",
        "print('-------- T3 ---------')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import losses\n",
        "\n",
        "def nonlinear_model(train, targets, epochs):\n",
        "  \"\"\"\n",
        "  Init the nonlinear model for this task. In this case it is a\n",
        "  Neural Network with two hidden layers.\n",
        "  :param train: the training set\n",
        "  :param targets: the test set\n",
        "  :param epochs: the number of epochs used to train the NN\n",
        "  :return: the trained Neural Netowrk on input data\n",
        "  \"\"\"\n",
        "  network = Sequential()\n",
        "  network.add(Dense(20, activation=\"relu\"))\n",
        "  network.add(Dense(13, activation=\"tanh\"))\n",
        "  network.add(Dense(1))\n",
        "  network.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
        "  network.fit(train, targets, epochs = epochs, verbose = 0)\n",
        "  return network\n",
        "\n",
        "# Create trained model\n",
        "network = nonlinear_model(X_train, y_train, 1200)\n",
        "\n",
        "# Save the model in a pickle file\n",
        "# Uncomment next two instructions to save the nonlinear model\n",
        "\"\"\"\n",
        "with open('nonlinear_regression.pickle', 'wb') as f:\n",
        "  pickle.dump(network, f, pickle.HIGHEST_PROTOCOL)\n",
        "\"\"\"\n",
        "\n",
        "# Generate prediction on test set and evaluate performance with MSE\n",
        "test_prediction = network.predict(X_test)\n",
        "test_performance = mean_squared_error(test_prediction, y_test)\n",
        "\n",
        "print('MSE on test set: {}'.format(test_performance))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sozbw8tY-rls"
      },
      "source": [
        "# Example on how to use baseline model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF-xBUdK-rls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce46be8-9434-428c-caae-b07c5c439f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n",
            "MSE on whole dataset: 0.014841441509163372\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import joblib\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates the mean squared error between the values in y_true and the values\n",
        "    in y_pred.\n",
        "    ### YOU CAN NOT EDIT THIS FUNCTION ###\n",
        "    :param y_true: Numpy array, the true target values from the test set;\n",
        "    :param y_pred: Numpy array, the values predicted by your model.\n",
        "    :return: float, the mean squared error between the two arrays.\n",
        "    \"\"\"\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "\n",
        "def load_model(filename):\n",
        "    \"\"\"\n",
        "    Loads a Scikit-learn model saved with joblib.dump.\n",
        "    This is just an example, you can write your own function to load the model.\n",
        "    Some examples can be found in src/utils.py.\n",
        "    :param filename: string, path to the file storing the model.\n",
        "    :return: the model.\n",
        "    \"\"\"\n",
        "    model = joblib.load(filename)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Load the data\n",
        "# This will be replaced with our private test data when grading the assignment\n",
        "\n",
        "# Load data from url\n",
        "url = 'https://drive.switch.ch/index.php/s/TeDwnbYsBKRuJjv/download'\n",
        "response = requests.get(url)\n",
        "data = np.load(io.BytesIO(response.content))\n",
        "\n",
        "# Alternatively yo can load the data from file\n",
        "# data_path = '../data/data.npz'\n",
        "# data = np.load(data_path)\n",
        "\n",
        "# x is a Numpy array of shape (n_samples, n_features) with the inputs\n",
        "x = data.f.x\n",
        "# y is a Numpy array of shape (n_samples, ) with the targets\n",
        "y = data.f.y\n",
        "\n",
        "# Load the trained model\n",
        "linear_model_path = './nonlinear_regression.pickle'\n",
        "linear_model = load_model(linear_model_path)\n",
        "\n",
        "# Change input\n",
        "ones = np.ones(shape=(x.shape[0], 1))\n",
        "sin_x2 = np.sin(x[:, 1]).reshape(-1,1)\n",
        "x1_times_x2 = np.multiply(x[:, 0], x[:, 1]).reshape(-1,1)\n",
        "x = np.hstack((ones, x, sin_x2, x1_times_x2)) \n",
        "\n",
        "# Predict on the given samples\n",
        "y_pred = linear_model.predict(x).flatten()\n",
        "\n",
        "############################################################################\n",
        "# STOP EDITABLE SECTION: do not modify anything below this point.\n",
        "############################################################################\n",
        "\n",
        "# Evaluate the prediction using MSE\n",
        "mse = evaluate_predictions(y_pred, y)\n",
        "print(f'MSE on whole dataset: {mse}')\n",
        "\n",
        "# NOTE: NOW THIS CELL IS NOT WORKING SINCE YOU NEED TO CHANGE THE INPUT.\n",
        "# DO IT AND EVERYTHING RUNS SMOOTH\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}